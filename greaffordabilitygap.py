# -*- coding: utf-8 -*-
"""GREAffordabilityGap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BMf_C8LOfp2op3EJ80n5NH_fr4iMnJOe

# Working stuff
## Zillow data import and community filtering
"""

# Cell 1: Download and Filter Zillow Data
import re
import requests
import os
import pandas as pd
from datetime import datetime

# Step 1: Extract the CSV URL from Zillow
html_content = """
<a href="https://files.zillowstatic.com/research/public_csvs/zhvi/City_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv?t=1726591162">Download</a>
<a href="https://files.zillowstatic.com/research/public_csvs/zhvi/City_zhvi_uc_sfrcondo_tier_0.33_0.67_other_month.csv?t=1726591163">Download</a>
"""

regex = r'https:\/\/files\.zillowstatic\.com\/research\/public_csvs\/zhvi\/City_zhvi_uc_sfrcondo_tier_0\.33_0\.67_.*?\.csv'
match = re.search(regex, html_content)

if match:
    csv_url = match.group(0)
    print(f"CSV URL found: {csv_url}")

    # Step 2: Download the CSV file
    response = requests.get(csv_url)

    if response.status_code == 200:
        print("CSV file downloaded successfully.")

        # Step 3: Save the CSV file to the current directory
        save_directory = "./"
        os.makedirs(save_directory, exist_ok=True)

        save_path = os.path.join(save_directory, "City_zhvi_data.csv")

        with open(save_path, "wb") as file:
            file.write(response.content)
        print(f"CSV file saved at '{save_path}'")

        # Step 4: Load the CSV using pandas and filter for RegionID 397274
        df = pd.read_csv(save_path)
        filtered_df = df[df['RegionID'] == 397274]

        if not filtered_df.empty:
            # Save the filtered data to a new CSV file
            filtered_save_path = os.path.join(save_directory, "Community_zhvi_filter.csv")
            filtered_df.to_csv(filtered_save_path, index=False)
            print(f"Filtered data saved at '{filtered_save_path}'")
        else:
            print("No row found with RegionID 397274.")
    else:
        print(f"Failed to download CSV file. Status code: {response.status_code}")
else:
    print("No matching CSV URL found.")

"""## Normalize Zillow dates"""

# Cell 2: Filter and Normalize Dates
import pandas as pd
from datetime import datetime

# Load the filtered CSV file
filtered_df = pd.read_csv("Community_zhvi_filter.csv")

# Identify date columns (columns that can be parsed as dates)
date_columns = [col for col in filtered_df.columns if re.match(r'^\d{4}-\d{2}$', col)]

# Create a dictionary to store the processed data
processed_data = {col: filtered_df[col].values[0] for col in filtered_df.columns if col not in date_columns}

# Process date columns
for col in date_columns:
    date = datetime.strptime(col + '-01', '%Y-%m-%d')
    if date >= datetime(2010, 1, 1):
        normalized_date = date.strftime('%Y-%m-01')
        processed_data[normalized_date] = filtered_df[col].values[0]

# Create a new DataFrame with the processed data
final_df = pd.DataFrame([processed_data])

# Sort columns by date
date_columns = [col for col in final_df.columns if re.match(r'^\d{4}-\d{2}-\d{1,2}$', col)]
non_date_columns = [col for col in final_df.columns if col not in date_columns]
sorted_date_columns = sorted(date_columns)

# Filter date columns to only include those from 2010 onwards
sorted_date_columns = [col for col in sorted_date_columns if datetime.strptime(col, '%Y-%m-%d') >= datetime(2010, 1, 1)]

# Combine non-date columns with filtered and sorted date columns
final_df = final_df[non_date_columns + sorted_date_columns]

# Rename the date columns to ensure they're displayed correctly
final_df.rename(columns={col: datetime.strptime(col, '%Y-%m-%d').strftime('%Y-%m-01') for col in sorted_date_columns}, inplace=True)

print("Zillow data processed successfully.")
print(final_df.head())

# Save the final processed data
final_save_path = "Community_zhvi_processed.csv"
final_df.to_csv(final_save_path, index=False)
print(f"Final processed data saved at '{final_save_path}'")

"""## FRED data import and add to Zillow data"""

# Cell 3: Combine Zillow and FRED Data
import requests
import pandas as pd
import re
import xml.etree.ElementTree as ET
from datetime import datetime

# Load the processed Zillow data
zillow_df = pd.read_csv("Community_zhvi_processed.csv")

# Identify date columns
date_columns = [col for col in zillow_df.columns if re.match(r'^\d{4}-\d{2}-\d{1,2}$', col)]

# Melt the DataFrame to have a single date column
zillow_melted = pd.melt(zillow_df, id_vars=[col for col in zillow_df.columns if col not in date_columns],
                        var_name='Date', value_name='Home_Value')
zillow_melted['Date'] = pd.to_datetime(zillow_melted['Date'])

# Sort the melted DataFrame by date
zillow_melted = zillow_melted.sort_values('Date')

# Load the FRED data
# FRED API parameters
series_id = 'MORTGAGE30US'
api_key = '6db6853421f70b64e8a5674702a27d1f'
frequency = 'm'

# Construct the API URL
url = f"https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&frequency={frequency}"

# Make the API request
response = requests.get(url)

# Parse the XML response
root = ET.fromstring(response.content)

# Extract the dates and values
dates = []
rates = []
for observation in root.findall('.//observation'):
    date = datetime.strptime(observation.get('date'), '%Y-%m-%d')
    value = observation.get('value')
    if value != '.':  # Check if the value is not a dot
        try:
            value = float(value)
            dates.append(date)
            rates.append(value)
        except ValueError:
            print(f"Skipping invalid value: {value} for date {date}")
    else:
        print(f"Skipping missing value for date {date}")

# Create a DataFrame for mortgage rates
mortgage_rates = pd.DataFrame({'Date': dates, 'Mortgage_Rate': rates})

# Set the date as the index
mortgage_rates.set_index('Date', inplace=True)

# Filter FRED data to match Zillow date range
start_date = zillow_melted['Date'].min()
end_date = zillow_melted['Date'].max()
mortgage_rates_filtered = mortgage_rates[(mortgage_rates.index >= start_date) & (mortgage_rates.index <= end_date)]

# Merge Zillow and FRED data
combined_data = pd.merge(zillow_melted, mortgage_rates_filtered, left_on='Date', right_index=True, how='left')

# Forward fill any missing mortgage rates
combined_data['Mortgage_Rate'] = combined_data['Mortgage_Rate'].ffill()

# Sort the combined data by date
combined_data = combined_data.sort_values('Date')

print("Zillow and FRED data combined successfully.")
print(combined_data.head())

# Save the combined data
combined_save_path = "Combined_Zillow_FRED_data.csv"
combined_data.to_csv(combined_save_path, index=False)
print(f"Combined data saved at '{combined_save_path}'")

"""## Add custom inputs and merge
### Grab the incomes
"""

import requests
import pandas as pd
import numpy as np
from io import StringIO

# Step 1: Load MEDIAN_HH_INCOME data from Google Sheets
sheet_id = "1B4Q6JTfmiYhn7NFfobCFxLthKE2k-0QeBo_yOdpzWhQ"
url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
response = requests.get(url)
response.raise_for_status()  # Check for errors in request

# Read the CSV data into a pandas DataFrame
df_income = pd.read_csv(StringIO(response.text))

# Convert the 'date' column to datetime and set it as index
df_income['date'] = pd.to_datetime(df_income['date'])
df_income.set_index('date', inplace=True)

# Remove commas from 'MEDIAN_HH_INCOME' and convert it to numeric
df_income['MEDIAN_HH_INCOME'] = df_income['MEDIAN_HH_INCOME'].replace(',', '', regex=True).astype(float)

# Step 2: Load the Zillow and FRED combined CSV data from local directory
csv_file_path = 'Combined_Zillow_FRED_data.csv'
df_csv = pd.read_csv(csv_file_path)

# Convert the 'Date' column in the CSV to datetime and set it as the index
df_csv['Date'] = pd.to_datetime(df_csv['Date'])  # Correct reference to 'Date' (capitalized)
df_csv.set_index('Date', inplace=True)

# Step 3: Reindex df_income with the full date range from df_csv
df_income_full_range = df_income.reindex(df_csv.index.union(df_income.index))

# Interpolate missing values for MEDIAN_HH_INCOME
df_income_full_range['MEDIAN_HH_INCOME'] = df_income_full_range['MEDIAN_HH_INCOME'].interpolate(method='linear')

# Step 4: Extrapolate beyond 2022 based on the slope of the last few years of data
# Get the slope and intercept using linear regression on known data (2010-2022)
years = (df_income.index - pd.Timestamp('2010-01-01')).days / 365.25  # Convert dates to fractional years
known_values = df_income['MEDIAN_HH_INCOME'].dropna()

# Linear regression to find slope and intercept
slope, intercept = np.polyfit(years, known_values, 1)

# Find the extrapolation range in the full dataset (after 2022-01-01)
extrapolation_years = (df_income_full_range.index - pd.Timestamp('2010-01-01')).days / 365.25
df_income_full_range.loc[df_income_full_range.index > '2022-01-01', 'MEDIAN_HH_INCOME'] = (
    slope * extrapolation_years[df_income_full_range.index > '2022-01-01'] + intercept
)

# Step 5: Combine the interpolated and extrapolated values with the original CSV data
df_csv['MEDIAN_HH_INCOME'] = df_income_full_range['MEDIAN_HH_INCOME']

# Step 6: Save the final dataset to a new CSV file
output_path = 'Updated_Zillow_FRED_Median_HH_Income.csv'
df_csv.to_csv(output_path)

# Step 7: Print the first few rows of the updated CSV for inspection
print("First few rows of the updated data:")
print(df_csv.head())

# Display the path of the saved file
print(f"Updated data saved to: {output_path}")

"""## Get the constants from Google Sheets"""

import requests
import pandas as pd
from io import StringIO

# Google Sheet ID and specific sheet (gid) for the constants
sheet_id = "1B4Q6JTfmiYhn7NFfobCFxLthKE2k-0QeBo_yOdpzWhQ"
gid = "2107161646"  # GID for the constants sheet

# Construct the URL for the specific sheet
url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"

# Fetch the constants data
response = requests.get(url)
response.raise_for_status()  # Check for errors in request

# Read the CSV data into a pandas DataFrame
df_constants = pd.read_csv(StringIO(response.text), header=None)

# Print the constants DataFrame to inspect the structure
print("Constants DataFrame:")
print(df_constants)

# Step 2: Convert constants DataFrame into key-value pairs
constants = dict(zip(df_constants[0], df_constants[1]))

# Alternatively, load the constants into individual variables for direct use
DOWN_PAYMENT_PERCENT = constants['DOWN_PAYMENT_PERCENT']
LOAN_TERM_YEARS = constants['LOAN_TERM_YEARS']
PROPERTY_INSURANCE_RATE = constants['PROPERTY_INSURANCE_RATE']
MORTGAGE_INSURANCE_RATE = constants['MORTGAGE_INSURANCE_RATE']
PERCENT_OF_INCOME_FOR_HOUSING = constants['PERCENT_OF_INCOME_FOR_HOUSING']
PROPERTY_TAX_RATE = constants['PROPERTY_TAX_RATE']

# Print the constants to confirm they are loaded
print(f"DOWN_PAYMENT_PERCENT: {DOWN_PAYMENT_PERCENT}")
print(f"LOAN_TERM_YEARS: {LOAN_TERM_YEARS}")
print(f"PROPERTY_INSURANCE_RATE: {PROPERTY_INSURANCE_RATE}")
print(f"MORTGAGE_INSURANCE_RATE: {MORTGAGE_INSURANCE_RATE}")
print(f"PERCENT_OF_INCOME_FOR_HOUSING: {PERCENT_OF_INCOME_FOR_HOUSING}")
print(f"PROPERTY_TAX_RATE: {PROPERTY_TAX_RATE}")

"""## Use a solver to identify the affordable home price

### Selected monthly cost of ownership
The amounts reported include everything paid to the lender including principal and interest payments, real estate taxes, fire, hazard, and flood insurance payments, and mortgage insurance premiums. ([source](https://www.socialexplorer.com/data/ACS2016_5yr/documentation/27ca004e-d1ea-4c55-b4e2-68ce533d712d#b4231998-9e0c-474f-8905-d999991316e6))
"""

import pandas as pd
import numpy as np
from scipy.optimize import brentq

# Constants from previous step (already loaded into a dictionary called `constants`)
DOWN_PAYMENT_PERCENT = constants['DOWN_PAYMENT_PERCENT']
LOAN_TERM_YEARS = constants['LOAN_TERM_YEARS']
PROPERTY_INSURANCE_RATE = constants['PROPERTY_INSURANCE_RATE']
MORTGAGE_INSURANCE_RATE = constants['MORTGAGE_INSURANCE_RATE']
PERCENT_OF_INCOME_FOR_HOUSING = constants['PERCENT_OF_INCOME_FOR_HOUSING']
PROPERTY_TAX_RATE = constants['PROPERTY_TAX_RATE']
MONTHS_IN_YEAR = 12  # Constant value

# Function to calculate monthly payment for a mortgage
def calculate_monthly_payment(principal, annual_rate, term_years):
    monthly_rate = annual_rate / (100 * MONTHS_IN_YEAR)  # Convert annual rate to monthly decimal
    num_payments = term_years * MONTHS_IN_YEAR
    if monthly_rate == 0:
        return principal / num_payments
    return principal * (monthly_rate * (1 + monthly_rate)**num_payments) / ((1 + monthly_rate)**num_payments - 1)

# Solver function to calculate the affordable home price
def calculate_affordable_home_price(annual_income, annual_interest_rate):
    monthly_income = annual_income / MONTHS_IN_YEAR
    monthly_housing_budget = monthly_income * PERCENT_OF_INCOME_FOR_HOUSING

    def monthly_costs(home_value):
        loan_amount = home_value * (1 - DOWN_PAYMENT_PERCENT)
        monthly_mortgage = calculate_monthly_payment(loan_amount, annual_interest_rate, LOAN_TERM_YEARS)
        monthly_property_tax = (home_value * PROPERTY_TAX_RATE) / MONTHS_IN_YEAR
        monthly_property_insurance = (home_value * PROPERTY_INSURANCE_RATE) / MONTHS_IN_YEAR
        monthly_mortgage_insurance = (loan_amount * MORTGAGE_INSURANCE_RATE) / MONTHS_IN_YEAR if DOWN_PAYMENT_PERCENT < 0.2 else 0

        return monthly_mortgage + monthly_property_tax + monthly_property_insurance + monthly_mortgage_insurance

    def affordable_home_equation(home_value):
        return monthly_costs(home_value) - monthly_housing_budget

    # Use brentq to find the root of the equation (where monthly costs equal the budget)
    try:
        affordable_home_value = brentq(affordable_home_equation, 0, annual_income * 10)
    except ValueError:
        # If no solution is found, return 0 (no affordable home at this income and interest rate)
        return 0

    return affordable_home_value

# Load the CSV data with income and mortgage rates
csv_file_path = 'Updated_Zillow_FRED_Median_HH_Income.csv'
df = pd.read_csv(csv_file_path)

# Ensure the 'Date' column is properly preserved by resetting the index
df = df.reset_index()

# Apply the solver to each row in the DataFrame
df['Affordable_Home_Price'] = df.apply(lambda row: calculate_affordable_home_price(row['MEDIAN_HH_INCOME'], row['Mortgage_Rate']), axis=1)

# Calculate the dollar difference between ZHVI and Affordable Home Price
df['ZHVI_Affordable_Difference'] = df['Home_Value'] - df['Affordable_Home_Price']

# Ensure 'Date' column is converted properly to datetime for output
df['Date'] = pd.to_datetime(df['Date'])

# Display the first few rows of the updated DataFrame
print(df.head())

# Save the updated DataFrame to a new CSV file
output_path = 'c_income_zhvi_mortgage_comprehensive_affordability.csv'
df.to_csv(output_path, index=False)
print(f"\nCSV file '{output_path}' has been created.")

# Plot the data (optional, if you want to visualize it)
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(df['Date'], df['Home_Value'], label='ZHVI (Home Value)')
plt.plot(df['Date'], df['Affordable_Home_Price'], label='Affordable Home Price')
plt.title('ZHVI vs Affordable Home Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price ($)')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(df['Date'], df['ZHVI_Affordable_Difference'])
plt.title('Difference between ZHVI and Affordable Home Price Over Time')
plt.xlabel('Date')
plt.ylabel('Difference ($)')
plt.axhline(y=0, color='r', linestyle='--')  # Add a horizontal line at y=0
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Additional statistics
print(f"\nCurrent difference (latest date): ${df['ZHVI_Affordable_Difference'].iloc[-1]:.2f}")
print(f"Average difference: ${df['ZHVI_Affordable_Difference'].mean():.2f}")
print(f"Median difference: ${df['ZHVI_Affordable_Difference'].median():.2f}")
print(f"Maximum difference: ${df['ZHVI_Affordable_Difference'].max():.2f} on {df.loc[df['ZHVI_Affordable_Difference'].idxmax(), 'Date']}")
print(f"Minimum difference: ${df['ZHVI_Affordable_Difference'].min():.2f} on {df.loc[df['ZHVI_Affordable_Difference'].idxmin(), 'Date']}")

# Calculate percentage of time ZHVI is above Affordable Price
percent_above = (df['ZHVI_Affordable_Difference'] > 0).mean() * 100
print(f"\nPercentage of time ZHVI is above Affordable Price: {percent_above:.2f}%")

import requests
import base64

# GitHub credentials and repo details
GITHUB_TOKEN = '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'  # Replace with your GitHub PAT
REPO_OWNER = 'CommunityScale'  # Replace with your GitHub username or organization
REPO_NAME = 'Greenfield'  # Replace with your repository name
FILE_PATH = 'c_income_zhvi_mortgage_comprehensive_affordability.csv'  # Path to the local CSV file
BRANCH = 'main'  # The branch where you want to push the file
GITHUB_FILE_PATH = 'c_income_zhvi_mortgage_comprehensive_affordability.csv'  # Path in the GitHub repo

# Read the contents of the CSV file
with open(FILE_PATH, 'rb') as file:
    content = file.read()
    encoded_content = base64.b64encode(content).decode('utf-8')

# GitHub API endpoint for creating/updating a file
url = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{GITHUB_FILE_PATH}'

# Prepare the request payload
payload = {
    "message": "Upload affordability analysis CSV",
    "content": encoded_content,
    "branch": BRANCH
}

# Send the request to GitHub API
response = requests.put(url, json=payload, headers={
    "Authorization": f"token {GITHUB_TOKEN}",
    "Content-Type": "application/json"
})

# Check the response
if response.status_code == 201:
    print("File successfully uploaded.")
elif response.status_code == 200:
    print("File updated successfully.")
else:
    print(f"Failed to upload file: {response.status_code}")
    print(response.text)